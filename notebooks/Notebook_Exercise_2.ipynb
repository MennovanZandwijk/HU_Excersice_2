{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uitwerking Excerise 2\n",
    "Student: Menno van Zandwijk <br /> Studentnummer: 1807647  <br />  Datum: 14-06-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Introductie\n",
    "\n",
    "In dit notebook zijn de uitverkingen weergegeven van excerise twee waarbij een dataloader en data itereator zijn geprogrammeerd voor de EEG EYE dataset. De betreffende classes zijn weergegeven in de file 'data_tools' die is opgeslagen in de src-folder. In dit notebook zijn de classes beschreven, worden ze aangeroepen en de uitkomsten geanalyseerd. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Importen functies en variabelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:41:24.014000: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-14 10:41:24.014033: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from scipy.io import arff\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.data import (\n",
    "    data_tools,\n",
    ")  # Importeren van functies en classes afkomstig van het bestand 'data_tools' die is opgeslagen in de src-folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middels onderstaande functie afkomstig uit het bestand 'data_tools' wordt de ruwe data geïmporteerd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:41:35.442 | INFO     | src.data.data_tools:get_eeg:30 - Data is downloaded to ../data/raw/datasets/eeg_data.\n"
     ]
    }
   ],
   "source": [
    "data = arff.loadarff(data_tools.get_eeg())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De dataset bevat 14980 observaties met per observatie 15 dimensies. De eerste veertien dimensies bevat registraties van hersenactiviteiten, de vijftiende observatie betreft het label of een oog tijdens de observatie open of dicht was.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"De dataset bevat {len(data[0])} observaties met per observatie {len(data[0][1])} dimensies. De eerste veertien dimensies bevat registraties van hersenactiviteiten, de vijftiende observatie betreft het label of een oog tijdens de observatie open of dicht was.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Data loader\n",
    "\n",
    "Het doel van de dataloader is om de dataset op te delen in chunks waarbij het label (oog open of dicht) gelijk is. De dataset betreft een timeserie waardoor bij het 'chunken' van de data gekeken dient de worden naar de volgorde van de obervaties. Conform de opdracht dienen observaties met eenzelfde label toegevoegd te worden aan een chunk en dient een nieuwe chunk te worden aangemaakt zodra het label van een observatie wijzigt. Vervolgens dienen alle opvolgende observaties met het gewijzigde label weer verzameld te worden in een chunk waarna dit proces zich herhaalt totdat alle observaties zijn opgeslagen. Om de observaties te kunnen chunken is gebruik gemaakt van een for-loop die door de observaties itereert. De betreffende for-loop is hieronder weergegeven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:41:35.922 | INFO     | src.data.data_tools:get_eeg:30 - Data is downloaded to ../data/raw/datasets/eeg_data.\n"
     ]
    }
   ],
   "source": [
    "data = arff.loadarff(data_tools.get_eeg())\n",
    "current_label = int(data[0][0][14])  # index 14 = label\n",
    "EEG_batch = []  # Lege lijst waarin meerdere observaties worden opgeslagen\n",
    "EEG_batches = []  # Lege lijst waarin meerdere batches in worden samengevoegd.\n",
    "for record in data[0]:\n",
    "    if int(record[14]) == current_label:\n",
    "        EEG_values = (\n",
    "            []\n",
    "        )  # Lege lijst waarin de EEG_values van een bepaalde observatie in kunnen worden opgeslagen.\n",
    "        for index, i in enumerate(record):\n",
    "            if index != 14:\n",
    "                EEG_values.append(i)\n",
    "        EEG_values = torch.Tensor(EEG_values)\n",
    "        EEG_batch.append(EEG_values)\n",
    "    else:\n",
    "        EEG_batch_label = (current_label, torch.stack(EEG_batch))\n",
    "        EEG_batches.append(EEG_batch_label)\n",
    "        current_label = int(record[14])\n",
    "        EEG_batch = (\n",
    "            []\n",
    "        )  # Lege lijst waarin meerdere observaties in kunnen worden opgeslagen.\n",
    "        EEG_values = (\n",
    "            []\n",
    "        )  # Lege lijst waarin de EEG_values van een bepaalde observatie in kunnen worden opgeslagen.\n",
    "        for index, i in enumerate(record):\n",
    "            if index != 14:\n",
    "                EEG_values.append(i)\n",
    "        EEG_values = torch.Tensor(EEG_values)\n",
    "EEG_batch_label = (current_label, torch.stack(EEG_batch))\n",
    "EEG_batches.append(EEG_batch_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De for-loop heeft de 14980 observaties opgedeeld in 24 chunks.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"De for-loop heeft de {len(data[0])} observaties opgedeeld in {len(EEG_batches)} chunks.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hiervoor beschreven for-loop is vervolgens geïmplementeerd in de functie 'process_data' die in class 'EEGDataset' is opgenomen. De class 'EEGDataset' heeft daarbij de functies afkomstig van de class 'BaseDataset' inheritance. In onderstaande query is de ruwe dataset door de class gehaald om de 24 chunks te maken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-14 10:41:36.789 | INFO     | src.data.data_tools:get_eeg:30 - Data is downloaded to ../data/raw/datasets/eeg_data.\n"
     ]
    }
   ],
   "source": [
    "dataloader = data_tools.EEGDataset(datasetpath=data_tools.get_eeg())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middels de __len__ functie kan vervolgens de lengte (lees: aantal chunks) worden opgehaald."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.__len__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middels de __getitem__ functie kan vervolgens de data uit een specifieke chunk worden opgehaald. Hieruit blijkt dat de chunks tuples zijn met een label en tensor met meerdere observaties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[4329.2300, 4009.2300, 4289.2300,  ..., 4280.5098, 4635.8999,\n",
       "          4393.8501],\n",
       "         [4324.6201, 4004.6201, 4293.8501,  ..., 4279.4902, 4632.8198,\n",
       "          4384.1001],\n",
       "         [4327.6899, 4006.6699, 4295.3799,  ..., 4282.0498, 4628.7202,\n",
       "          4389.2300],\n",
       "         ...,\n",
       "         [4468.2100, 4044.6201, 4305.1299,  ..., 4367.6899, 4833.8501,\n",
       "          4571.7900],\n",
       "         [4461.0298, 4041.0300, 4300.0000,  ..., 4365.1299, 4826.6699,\n",
       "          4558.4600],\n",
       "         [4452.8198, 4032.3101, 4295.3799,  ..., 4353.3301, 4808.2100,\n",
       "          4549.2300]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(dataloader.__getitem__(0)))\n",
    "dataloader.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middels de __shape__ blijkt dat de eerste chunk 188 observaties bevat met per observatie veertien dimensies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([188, 14])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader[0][1].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Data iterater\n",
    "\n",
    "Uit onderstaande query blijkt dat het aantal observaties per chunk verschilt en daardoor problemen kunnen ontstaan indien de chunks door een batch loop worden gehaald. Middels het windowen van de observaties is het mogelijk om gelijke batches te creëren die geschikt zijn om in te lezen in een model. In deze paragraaf zijn de navolgende twee manieren van windowing toegepast:\n",
    "- Windowing zonder padding\n",
    "- Windowing met padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1 heeft 188 observaties.\n",
      "Chunk 2 heeft 682 observaties.\n",
      "Chunk 3 heeft 464 observaties.\n",
      "Chunk 4 heeft 301 observaties.\n",
      "Chunk 5 heeft 537 observaties.\n",
      "Chunk 6 heeft 456 observaties.\n",
      "Chunk 7 heeft 266 observaties.\n",
      "Chunk 8 heeft 26 observaties.\n",
      "Chunk 9 heeft 414 observaties.\n",
      "Chunk 10 heeft 1009 observaties.\n",
      "Chunk 11 heeft 891 observaties.\n",
      "Chunk 12 heeft 683 observaties.\n",
      "Chunk 13 heeft 724 observaties.\n",
      "Chunk 14 heeft 2400 observaties.\n",
      "Chunk 15 heeft 2050 observaties.\n",
      "Chunk 16 heeft 970 observaties.\n",
      "Chunk 17 heeft 651 observaties.\n",
      "Chunk 18 heeft 42 observaties.\n",
      "Chunk 19 heeft 204 observaties.\n",
      "Chunk 20 heeft 51 observaties.\n",
      "Chunk 21 heeft 1188 observaties.\n",
      "Chunk 22 heeft 71 observaties.\n",
      "Chunk 23 heeft 669 observaties.\n",
      "Chunk 24 heeft 20 observaties.\n"
     ]
    }
   ],
   "source": [
    "for i in range(dataloader.__len__()):\n",
    "    print(f\"Chunk {i+1} heeft {len(dataloader[i][1])} observaties.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 Windowing zonder padding\n",
    "\n",
    "Het doel van windowing is om op basis van de ongelijke chunks batches te creëren met een gelijke batch size. Middels onderstaande query worden de observaties in iedere chunk gewindowed met een window size van vijf. De betekent dat iedere batch vijf observaties bevat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_full = []\n",
    "window_size = 5\n",
    "for i in range(len(dataloader)):\n",
    "    n_window = len(dataloader[i][1]) - window_size + 1\n",
    "    time = torch.arange(0, window_size).reshape(1, -1)\n",
    "    window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "    idx = time + window\n",
    "    window_out = dataloader[i][1][idx]\n",
    "    window_out_label = (dataloader[i][0], window_out)\n",
    "    window_full.append(window_out_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De hiervoor beschreven window functie is vervolgens geïmplementeerd in de functie 'window' die in de class  'BaseDataIteratorWindowing' is opgenomen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_windowing = data_tools.BaseDataIteratorWindowing(dataloader, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Door het windowen bevat de eerste chunk nu de volgende tensor: torch.Size([184, 5, 14]). Deze tensor bevat dus 184 batches met ieder 5 observaties en 14 dimensies.\n"
     ]
    }
   ],
   "source": [
    "x, y = dataloader_windowing[0]\n",
    "print(\n",
    "    f\"Door het windowen bevat de eerste chunk nu de volgende tensor: {y.shape}. Deze tensor bevat dus {len(dataloader_windowing[0][1])} batches met ieder {len(dataloader_windowing[0][1][1])} observaties en {len(dataloader_windowing[0][1][1][1])} dimensies.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middels onderstaande query is de werking van windowing goed zichtbaar. Het eerste window bevat de eerste vijf observaties uit de chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4329.2300, 4009.2300, 4289.2300, 4148.2100, 4350.2598, 4586.1499,\n",
      "         4096.9199, 4641.0298, 4222.0498, 4238.4600, 4211.2798, 4280.5098,\n",
      "         4635.8999, 4393.8501],\n",
      "        [4324.6201, 4004.6201, 4293.8501, 4148.7202, 4342.0498, 4586.6699,\n",
      "         4097.4399, 4638.9702, 4210.7700, 4226.6699, 4207.6899, 4279.4902,\n",
      "         4632.8198, 4384.1001],\n",
      "        [4327.6899, 4006.6699, 4295.3799, 4156.4102, 4336.9199, 4583.5898,\n",
      "         4096.9199, 4630.2598, 4207.6899, 4222.0498, 4206.6699, 4282.0498,\n",
      "         4628.7202, 4389.2300],\n",
      "        [4328.7202, 4011.7900, 4296.4102, 4155.8999, 4343.5898, 4582.5601,\n",
      "         4097.4399, 4630.7700, 4217.4399, 4235.3799, 4210.7700, 4287.6899,\n",
      "         4632.3101, 4396.4102],\n",
      "        [4326.1499, 4011.7900, 4292.3101, 4151.2798, 4347.6899, 4586.6699,\n",
      "         4095.8999, 4627.6899, 4210.7700, 4244.1001, 4212.8198, 4288.2100,\n",
      "         4632.8198, 4398.4600]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4329.2300, 4009.2300, 4289.2300, 4148.2100, 4350.2598, 4586.1499,\n",
       "         4096.9199, 4641.0298, 4222.0498, 4238.4600, 4211.2798, 4280.5098,\n",
       "         4635.8999, 4393.8501],\n",
       "        [4324.6201, 4004.6201, 4293.8501, 4148.7202, 4342.0498, 4586.6699,\n",
       "         4097.4399, 4638.9702, 4210.7700, 4226.6699, 4207.6899, 4279.4902,\n",
       "         4632.8198, 4384.1001],\n",
       "        [4327.6899, 4006.6699, 4295.3799, 4156.4102, 4336.9199, 4583.5898,\n",
       "         4096.9199, 4630.2598, 4207.6899, 4222.0498, 4206.6699, 4282.0498,\n",
       "         4628.7202, 4389.2300],\n",
       "        [4328.7202, 4011.7900, 4296.4102, 4155.8999, 4343.5898, 4582.5601,\n",
       "         4097.4399, 4630.7700, 4217.4399, 4235.3799, 4210.7700, 4287.6899,\n",
       "         4632.3101, 4396.4102],\n",
       "        [4326.1499, 4011.7900, 4292.3101, 4151.2798, 4347.6899, 4586.6699,\n",
       "         4095.8999, 4627.6899, 4210.7700, 4244.1001, 4212.8198, 4288.2100,\n",
       "         4632.8198, 4398.4600]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataloader[0][1][0:5])\n",
    "dataloader_windowing[0][1][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het tweede window bevat de observaties twee t/m zes zoals hieronder weergeven.  De window schuift namelijk steeds een observaties op tot het einde.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4329.2300, 4009.2300, 4289.2300, 4148.2100, 4350.2598, 4586.1499,\n",
      "         4096.9199, 4641.0298, 4222.0498, 4238.4600, 4211.2798, 4280.5098,\n",
      "         4635.8999, 4393.8501],\n",
      "        [4324.6201, 4004.6201, 4293.8501, 4148.7202, 4342.0498, 4586.6699,\n",
      "         4097.4399, 4638.9702, 4210.7700, 4226.6699, 4207.6899, 4279.4902,\n",
      "         4632.8198, 4384.1001],\n",
      "        [4327.6899, 4006.6699, 4295.3799, 4156.4102, 4336.9199, 4583.5898,\n",
      "         4096.9199, 4630.2598, 4207.6899, 4222.0498, 4206.6699, 4282.0498,\n",
      "         4628.7202, 4389.2300],\n",
      "        [4328.7202, 4011.7900, 4296.4102, 4155.8999, 4343.5898, 4582.5601,\n",
      "         4097.4399, 4630.7700, 4217.4399, 4235.3799, 4210.7700, 4287.6899,\n",
      "         4632.3101, 4396.4102],\n",
      "        [4326.1499, 4011.7900, 4292.3101, 4151.2798, 4347.6899, 4586.6699,\n",
      "         4095.8999, 4627.6899, 4210.7700, 4244.1001, 4212.8198, 4288.2100,\n",
      "         4632.8198, 4398.4600],\n",
      "        [4321.0298, 4004.6201, 4284.1001, 4153.3301, 4345.6401, 4587.1802,\n",
      "         4093.3301, 4616.9199, 4202.5601, 4232.8198, 4209.7402, 4281.0298,\n",
      "         4628.2100, 4389.7402]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4324.6201, 4004.6201, 4293.8501, 4148.7202, 4342.0498, 4586.6699,\n",
       "         4097.4399, 4638.9702, 4210.7700, 4226.6699, 4207.6899, 4279.4902,\n",
       "         4632.8198, 4384.1001],\n",
       "        [4327.6899, 4006.6699, 4295.3799, 4156.4102, 4336.9199, 4583.5898,\n",
       "         4096.9199, 4630.2598, 4207.6899, 4222.0498, 4206.6699, 4282.0498,\n",
       "         4628.7202, 4389.2300],\n",
       "        [4328.7202, 4011.7900, 4296.4102, 4155.8999, 4343.5898, 4582.5601,\n",
       "         4097.4399, 4630.7700, 4217.4399, 4235.3799, 4210.7700, 4287.6899,\n",
       "         4632.3101, 4396.4102],\n",
       "        [4326.1499, 4011.7900, 4292.3101, 4151.2798, 4347.6899, 4586.6699,\n",
       "         4095.8999, 4627.6899, 4210.7700, 4244.1001, 4212.8198, 4288.2100,\n",
       "         4632.8198, 4398.4600],\n",
       "        [4321.0298, 4004.6201, 4284.1001, 4153.3301, 4345.6401, 4587.1802,\n",
       "         4093.3301, 4616.9199, 4202.5601, 4232.8198, 4209.7402, 4281.0298,\n",
       "         4628.2100, 4389.7402]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataloader[0][1][0:6])\n",
    "dataloader_windowing[0][1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De eerste chunk van de dataloader bevat 188 observaties, de eerste chunk na windowing maar 184 windows. Dit verschil wordt veroorzaakt doordat aan het eind van de eerste chunck niet voldoende observaties beschikbaar zijn om nog volledige windows te creëren.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"De eerste chunk van de dataloader bevat {len(dataloader[0][1])} observaties, de eerste chunk na windowing maar {len(window_full[0][1])} windows. Dit verschil wordt veroorzaakt doordat aan het eind van de eerste chunck niet voldoende observaties beschikbaar zijn om nog volledige windows te creëren.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Windowing met padding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals weergegeven in paragraaf 1.5 varieert het aantal observaties per chunk van 20 observaties (chunk 24) tot 2.400 observaties (chunk 14). Indien bij het windowen wordt gekozen voor een window size die groter is dan het aantal observaties in een chunk, ontstaat een error. Om deze error te voorkomen kan middels padding de lengte van een chunk worden vergroot met 0-waarden zodat de gekozen window size wel kan worden toegepast. In deze paragraaf is toegelicht op welke wijze de padding is toegevoegd aan de chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indien tijden het windowen wordt gekozen voor een te grote window size, ontstaat een error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "upper bound and larger bound inconsistent with step sign",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/Exercise_2/notebooks/Notebook_Exercise_2.ipynb Cell 35'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224d4c5f4d656e6e6f5f76616e5f5a616e6477696a6b227d/home/mladmin/code/Exercise_2/notebooks/Notebook_Exercise_2.ipynb#ch0000034vscode-remote?line=0'>1</a>\u001b[0m dataloader_windowing \u001b[39m=\u001b[39m data_tools\u001b[39m.\u001b[39;49mBaseDataIteratorWindowing(dataloader, \u001b[39m30\u001b[39;49m)\n",
      "File \u001b[0;32m~/code/Exercise_2/notebooks/../src/data/data_tools.py:91\u001b[0m, in \u001b[0;36mBaseDataIteratorWindowing.__init__\u001b[0;34m(self, dataset, window_size)\u001b[0m\n\u001b[1;32m     <a href='file:///home/mladmin/code/Exercise_2/notebooks/../src/data/data_tools.py?line=88'>89</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m dataset\n\u001b[1;32m     <a href='file:///home/mladmin/code/Exercise_2/notebooks/../src/data/data_tools.py?line=89'>90</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size \u001b[39m=\u001b[39m window_size\n\u001b[0;32m---> <a href='file:///home/mladmin/code/Exercise_2/notebooks/../src/data/data_tools.py?line=90'>91</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindow()\n",
      "File \u001b[0;32m~/code/Exercise_2/notebooks/../src/data/data_tools.py:103\u001b[0m, in \u001b[0;36mBaseDataIteratorWindowing.window\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/mladmin/code/Exercise_2/notebooks/../src/data/data_tools.py?line=100'>101</a>\u001b[0m n_window \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataset[i][\u001b[39m1\u001b[39m]) \u001b[39m-\u001b[39m window_size \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/mladmin/code/Exercise_2/notebooks/../src/data/data_tools.py?line=101'>102</a>\u001b[0m time \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, window_size)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/mladmin/code/Exercise_2/notebooks/../src/data/data_tools.py?line=102'>103</a>\u001b[0m window \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49marange(\u001b[39m0\u001b[39;49m, n_window)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///home/mladmin/code/Exercise_2/notebooks/../src/data/data_tools.py?line=103'>104</a>\u001b[0m idx \u001b[39m=\u001b[39m time \u001b[39m+\u001b[39m window\n\u001b[1;32m    <a href='file:///home/mladmin/code/Exercise_2/notebooks/../src/data/data_tools.py?line=104'>105</a>\u001b[0m window_out \u001b[39m=\u001b[39m dataset[i][\u001b[39m1\u001b[39m][idx]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: upper bound and larger bound inconsistent with step sign"
     ]
    }
   ],
   "source": [
    "dataloader_windowing = data_tools.BaseDataIteratorWindowing(dataloader, 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om deze error te voorkomen is ontstaande for-loop geprogrammeerd die, indien de window size groter is dan het aantal observaties in een chunk, padding toegevoegt. In onderstaande for-loop is een window size ingegeven van 30 observaties: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataloader\n",
    "window_size = 30\n",
    "list_padded = []\n",
    "for i in range(len(data)):\n",
    "    len_chunck = len(data[i][1])\n",
    "    padding_value = window_size - len_chunck\n",
    "    if padding_value > 0:\n",
    "        chuck_padding = F.pad(\n",
    "            input=data[i][1], pad=(0, 0, 0, padding_value), mode=\"constant\", value=0\n",
    "        )\n",
    "        padding_label = (data[i][0], chuck_padding)\n",
    "        list_padded.append(padding_label)\n",
    "    else:\n",
    "        chunck = (data[i][0], data[i][1])\n",
    "        list_padded.append(chunck)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 23 bevat zonder padding 20 observaties, op basis van een window size van 30 bevat chunk 23 na padding 30 observaties. De toename in het aantal observaties is veroorzaakt doordat padding is toegevoegd aan de betreffende chunk.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Chunk 23 bevat zonder padding {len(dataloader[23][1])} observaties, op basis van een window size van {window_size} bevat chunk 23 na padding {len(list_padded[23][1])} observaties. De toename in het aantal observaties is veroorzaakt doordat padding is toegevoegd aan de betreffende chunk.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Middels de hiervoor beschreven functie zijn er tijdens het windowen geen beperkingen meer aanwezig voor wat betreft batch size. De betreffende for-loop is middels een functie geïmplementeerd in de class 'BaseDataIteratorPaddingWindowing' waarin eerst padding wordt toegepast alvorens de window functie wordt aangeroepen. In onderstaande query wordt de betreffende class aangeroepen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_padding_windowing = data_tools.BaseDataIteratorPaddingWindowing(\n",
    "    dataloader, 30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Door de het windowen bevat de eerste chunk nu de volgende tensor: torch.Size([159, 30, 14]). Deze tensor bevat dus 159 batches met ieder 30 observaties en 14 dimensies.\n"
     ]
    }
   ],
   "source": [
    "x, y = dataloader_padding_windowing[0]\n",
    "print(\n",
    "    f\"Door de het windowen bevat de eerste chunk nu de volgende tensor: {y.shape}. Deze tensor bevat dus {len(dataloader_padding_windowing[0][1])} batches met ieder {len(dataloader_padding_windowing[0][1][0])} observaties en {len(dataloader_padding_windowing[0][1][0][0])} dimensies.\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "550ec4b71ff75bed3b323061f82716da608a4e59b5549b0d308795f2107f921d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deep-learning--4w6leLf-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
